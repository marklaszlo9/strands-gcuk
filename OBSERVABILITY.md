# Observability Guide

This document explains how to use the OpenTelemetry observability features integrated into the Envision Agent project using the `bedrock_agentcore_starter_toolkit`.

## Overview

The project includes comprehensive observability through OpenTelemetry instrumentation, providing:

- **Distributed Tracing** - Track requests across Lambda, AgentCore, and Bedrock services
- **Metrics Collection** - Monitor performance, token usage, and error rates
- **Structured Logging** - Enhanced logging with trace correlation
- **AWS X-Ray Integration** - Native AWS observability through OpenTelemetry

## Components with Observability

### 1. Custom Agent (`custom_agent.py`)
- **Spans**: `query_with_rag`, `knowledge_base_retrieve`, `bedrock_converse`
- **Attributes**: Query length, model ID, token usage, response length
- **Events**: Memory operations, knowledge base retrieval, error handling

### 2. Lambda Function (`lambda/agentcore_proxy.py`)
- **Spans**: `lambda_handler`, `process_agentcore_response`
- **Attributes**: HTTP method, request ID, payload size, response length
- **Events**: CORS handling, AgentCore invocation, response processing

### 3. Runtime Agent (`runtime_agent_main.py`)
- **Spans**: `main`, `interactive_session`, `process_query`
- **Attributes**: Configuration details, interaction count, health status
- **Events**: Agent initialization, user interactions, health checks

## Setup and Configuration

### 1. Install Dependencies

```bash
# Install observability dependencies
pip install bedrock_agentcore_starter_toolkit
pip install aws-opentelemetry-distro
pip install opentelemetry-api opentelemetry-sdk
```

### 2. Environment Variables

```bash
# Optional: Configure OpenTelemetry
export OTEL_SERVICE_NAME="envision-agent"
export OTEL_SERVICE_VERSION="1.0.0"
export OTEL_RESOURCE_ATTRIBUTES="service.name=envision-agent,service.version=1.0.0"

# AWS X-Ray (automatically configured when using aws-opentelemetry-distro)
export AWS_XRAY_TRACING_NAME="envision-agent"
export AWS_XRAY_CONTEXT_MISSING="LOG_ERROR"
```

### 3. Running with Instrumentation

#### Local Development
```bash
# Run the runtime agent with full instrumentation
opentelemetry-instrument python runtime_agent_main.py

# Run CLI with instrumentation
opentelemetry-instrument python agent_cli.py

# Health check with observability
opentelemetry-instrument python runtime_agent_main.py health
```

#### Docker Deployment
```dockerfile
# In your Dockerfile
CMD ["opentelemetry-instrument", "python", "runtime_agent_main.py"]
```

#### Lambda Deployment
The Lambda function automatically includes observability when the `aws-opentelemetry-distro` layer is present. The infrastructure includes the boto3 layer which provides OpenTelemetry support.

## Observability Features

### 1. Distributed Tracing

**Trace Structure:**
```
lambda_handler
├── process_agentcore_response
│   ├── knowledge_base_retrieve
│   ├── bedrock_converse
│   └── memory_operations
└── query_with_rag
    ├── load_memory_context
    ├── generate_response
    └── store_conversation
```

**Key Spans:**
- `lambda_handler` - Complete Lambda execution
- `query_with_rag` - RAG query processing
- `knowledge_base_retrieve` - Bedrock Knowledge Base calls
- `bedrock_converse` - Bedrock model invocation
- `process_agentcore_response` - Response processing

### 2. Metrics and Attributes

**Request Metrics:**
- `query_length` - Length of user query
- `response_length` - Length of generated response
- `contexts_found` - Number of knowledge base results
- `payload_size` - Size of AgentCore payload

**Performance Metrics:**
- `input_tokens` - Tokens sent to model
- `output_tokens` - Tokens generated by model
- `total_tokens` - Total token usage
- `attempt` - Retry attempt number

**Configuration Attributes:**
- `model_id` - Bedrock model identifier
- `has_knowledge_base` - Whether KB is configured
- `has_memory` - Whether memory is available
- `agent_arn` - AgentCore runtime ARN

### 3. Error Tracking

**Error Events:**
- `credential_refresh_required` - AWS credential issues
- `unexpected_error` - Unexpected exceptions
- `processing_error` - Response processing failures
- `error_occurred` - General error events

**Error Attributes:**
- `error_code` - AWS error code
- `error` - Error message
- `attempt` - Retry attempt when error occurred

## Monitoring and Alerting

### 1. AWS X-Ray Integration

When deployed to AWS, traces automatically appear in AWS X-Ray:

```bash
# View traces in AWS Console
aws xray get-trace-summaries --time-range-type TimeRangeByStartTime --start-time 2024-01-01T00:00:00 --end-time 2024-01-02T00:00:00
```

### 2. CloudWatch Metrics

Custom metrics are automatically sent to CloudWatch:

- `envision.agent.requests` - Request count
- `envision.agent.errors` - Error count
- `envision.agent.latency` - Response latency
- `envision.agent.tokens` - Token usage

### 3. Log Correlation

All logs include trace and span IDs for correlation:

```json
{
  "timestamp": "2024-01-01T12:00:00Z",
  "level": "INFO",
  "message": "Processing query with RAG",
  "trace_id": "1-5e1b4151-5ac6c58f5b5d4b5f5e1b4151",
  "span_id": "5ac6c58f5b5d4b5f",
  "service": "envision-agent"
}
```

## Troubleshooting

### 1. Missing Traces

**Problem**: No traces appearing in X-Ray
**Solution**: 
```bash
# Check if instrumentation is active
echo $OTEL_SERVICE_NAME

# Verify AWS credentials
aws sts get-caller-identity

# Check Lambda layer configuration
aws lambda get-function --function-name your-function-name
```

### 2. High Latency

**Problem**: Slow response times
**Solution**: Check spans for bottlenecks:
- `knowledge_base_retrieve` - KB query performance
- `bedrock_converse` - Model inference time
- `memory_operations` - AgentCore memory latency

### 3. Token Usage Monitoring

**Problem**: High token consumption
**Solution**: Monitor token attributes:
```bash
# Query CloudWatch for token metrics
aws logs filter-log-events --log-group-name /aws/lambda/your-function --filter-pattern "input_tokens"
```

## Best Practices

### 1. Span Naming
- Use descriptive, hierarchical names
- Include operation type (e.g., `bedrock_converse`, `knowledge_base_retrieve`)
- Keep names consistent across services

### 2. Attribute Management
- Add relevant business context
- Avoid PII in attributes
- Use consistent attribute names

### 3. Error Handling
- Always set span status on errors
- Include error details in events
- Use structured error attributes

### 4. Performance
- Minimize span creation overhead
- Use sampling for high-volume operations
- Monitor instrumentation impact

## Example Queries

### 1. Find Slow Requests
```sql
-- CloudWatch Insights query
fields @timestamp, @message, @duration
| filter @message like /query_with_rag/
| filter @duration > 5000
| sort @timestamp desc
```

### 2. Error Analysis
```sql
-- Find errors by type
fields @timestamp, error_code, @message
| filter @message like /ERROR/
| stats count() by error_code
```

### 3. Token Usage Trends
```sql
-- Monitor token consumption
fields @timestamp, input_tokens, output_tokens, total_tokens
| filter ispresent(total_tokens)
| stats avg(total_tokens), max(total_tokens) by bin(5m)
```

## Integration with Monitoring Tools

### 1. Grafana Dashboard
Create dashboards using CloudWatch metrics:
- Request rate and latency
- Error rates by type
- Token usage trends
- Knowledge base hit rates

### 2. Custom Alerts
Set up CloudWatch alarms:
```bash
# High error rate alert
aws cloudwatch put-metric-alarm \
  --alarm-name "EnvisionAgent-HighErrorRate" \
  --alarm-description "High error rate in Envision Agent" \
  --metric-name "Errors" \
  --namespace "AWS/Lambda" \
  --statistic "Sum" \
  --period 300 \
  --threshold 10 \
  --comparison-operator "GreaterThanThreshold"
```

### 3. Custom Metrics
Add business-specific metrics:
```python
from opentelemetry import metrics

meter = metrics.get_meter(__name__)
query_counter = meter.create_counter("envision_queries_total")
query_counter.add(1, {"query_type": "rag", "model": model_id})
```

This observability setup provides comprehensive monitoring and debugging capabilities for the Envision Agent, enabling proactive performance management and rapid issue resolution.